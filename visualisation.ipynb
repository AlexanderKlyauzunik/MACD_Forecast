{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>quote_volume</th>\n",
       "      <th>count</th>\n",
       "      <th>taker_buy_volume</th>\n",
       "      <th>taker_buy_quote_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1635725100000</th>\n",
       "      <td>191.43</td>\n",
       "      <td>192.02</td>\n",
       "      <td>191.37</td>\n",
       "      <td>192.02</td>\n",
       "      <td>2793.815</td>\n",
       "      <td>5.355669e+05</td>\n",
       "      <td>1297</td>\n",
       "      <td>1385.168</td>\n",
       "      <td>2.655765e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635725400000</th>\n",
       "      <td>192.02</td>\n",
       "      <td>193.32</td>\n",
       "      <td>191.93</td>\n",
       "      <td>193.01</td>\n",
       "      <td>10168.770</td>\n",
       "      <td>1.960809e+06</td>\n",
       "      <td>3851</td>\n",
       "      <td>5928.260</td>\n",
       "      <td>1.143253e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635725700000</th>\n",
       "      <td>192.98</td>\n",
       "      <td>193.76</td>\n",
       "      <td>192.92</td>\n",
       "      <td>193.62</td>\n",
       "      <td>8579.165</td>\n",
       "      <td>1.659771e+06</td>\n",
       "      <td>2904</td>\n",
       "      <td>3799.094</td>\n",
       "      <td>7.349429e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635726000000</th>\n",
       "      <td>193.60</td>\n",
       "      <td>193.72</td>\n",
       "      <td>193.02</td>\n",
       "      <td>193.37</td>\n",
       "      <td>4839.350</td>\n",
       "      <td>9.358926e+05</td>\n",
       "      <td>1951</td>\n",
       "      <td>2065.522</td>\n",
       "      <td>3.995075e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635726300000</th>\n",
       "      <td>193.36</td>\n",
       "      <td>193.69</td>\n",
       "      <td>193.31</td>\n",
       "      <td>193.39</td>\n",
       "      <td>4937.114</td>\n",
       "      <td>9.553264e+05</td>\n",
       "      <td>1758</td>\n",
       "      <td>2668.693</td>\n",
       "      <td>5.164217e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638315300000</th>\n",
       "      <td>208.33</td>\n",
       "      <td>208.91</td>\n",
       "      <td>208.15</td>\n",
       "      <td>208.77</td>\n",
       "      <td>4036.863</td>\n",
       "      <td>8.414236e+05</td>\n",
       "      <td>1373</td>\n",
       "      <td>1840.337</td>\n",
       "      <td>3.837659e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638315600000</th>\n",
       "      <td>208.78</td>\n",
       "      <td>209.18</td>\n",
       "      <td>208.77</td>\n",
       "      <td>209.00</td>\n",
       "      <td>2471.871</td>\n",
       "      <td>5.165802e+05</td>\n",
       "      <td>1203</td>\n",
       "      <td>1103.075</td>\n",
       "      <td>2.305155e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638315900000</th>\n",
       "      <td>209.00</td>\n",
       "      <td>209.19</td>\n",
       "      <td>207.60</td>\n",
       "      <td>207.73</td>\n",
       "      <td>5946.212</td>\n",
       "      <td>1.237775e+06</td>\n",
       "      <td>2159</td>\n",
       "      <td>1900.718</td>\n",
       "      <td>3.957291e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638316200000</th>\n",
       "      <td>207.75</td>\n",
       "      <td>208.45</td>\n",
       "      <td>207.10</td>\n",
       "      <td>208.16</td>\n",
       "      <td>8869.356</td>\n",
       "      <td>1.841825e+06</td>\n",
       "      <td>3102</td>\n",
       "      <td>4035.011</td>\n",
       "      <td>8.379854e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638316500000</th>\n",
       "      <td>208.15</td>\n",
       "      <td>208.38</td>\n",
       "      <td>207.57</td>\n",
       "      <td>207.96</td>\n",
       "      <td>4241.376</td>\n",
       "      <td>8.824013e+05</td>\n",
       "      <td>1824</td>\n",
       "      <td>2140.193</td>\n",
       "      <td>4.452919e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8639 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open    high     low   close     volume  quote_volume  count  \\\n",
       "open_time                                                                       \n",
       "1635725100000  191.43  192.02  191.37  192.02   2793.815  5.355669e+05   1297   \n",
       "1635725400000  192.02  193.32  191.93  193.01  10168.770  1.960809e+06   3851   \n",
       "1635725700000  192.98  193.76  192.92  193.62   8579.165  1.659771e+06   2904   \n",
       "1635726000000  193.60  193.72  193.02  193.37   4839.350  9.358926e+05   1951   \n",
       "1635726300000  193.36  193.69  193.31  193.39   4937.114  9.553264e+05   1758   \n",
       "...               ...     ...     ...     ...        ...           ...    ...   \n",
       "1638315300000  208.33  208.91  208.15  208.77   4036.863  8.414236e+05   1373   \n",
       "1638315600000  208.78  209.18  208.77  209.00   2471.871  5.165802e+05   1203   \n",
       "1638315900000  209.00  209.19  207.60  207.73   5946.212  1.237775e+06   2159   \n",
       "1638316200000  207.75  208.45  207.10  208.16   8869.356  1.841825e+06   3102   \n",
       "1638316500000  208.15  208.38  207.57  207.96   4241.376  8.824013e+05   1824   \n",
       "\n",
       "               taker_buy_volume  taker_buy_quote_volume  \n",
       "open_time                                                \n",
       "1635725100000          1385.168            2.655765e+05  \n",
       "1635725400000          5928.260            1.143253e+06  \n",
       "1635725700000          3799.094            7.349429e+05  \n",
       "1635726000000          2065.522            3.995075e+05  \n",
       "1635726300000          2668.693            5.164217e+05  \n",
       "...                         ...                     ...  \n",
       "1638315300000          1840.337            3.837659e+05  \n",
       "1638315600000          1103.075            2.305155e+05  \n",
       "1638315900000          1900.718            3.957291e+05  \n",
       "1638316200000          4035.011            8.379854e+05  \n",
       "1638316500000          2140.193            4.452919e+05  \n",
       "\n",
       "[8639 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "import pandas as pd\n",
    "import os\n",
    "from binance.client import Client\n",
    "import datetime, time\n",
    "import numpy as np\n",
    "\n",
    "# howLong = 2 * 365\n",
    "#     # Calculate the timestamps for the binance api function\n",
    "# untilThisDate = datetime.datetime.now()\n",
    "# sinceThisDate = untilThisDate - datetime.timedelta(days = howLong)\n",
    "# client = Client(api_key, api_secret)\n",
    "#     # Execute the query from binance - timestamps must be converted to strings !\n",
    "# candle = client.get_historical_klines(\"BNBBTC\", Client.KLINE_INTERVAL_1MINUTE, str(sinceThisDate), str(untilThisDate))\n",
    "\n",
    "#     # Create a dataframe to label all the columns returned by binance so we work with them later.\n",
    "# df = pd.DataFrame(candle, columns=['dateTime', 'open', 'high', 'low', 'close', 'volume', 'closeTime', 'quoteAssetVolume', 'numberOfTrades', 'takerBuyBaseVol', 'takerBuyQuoteVol', 'ignore'])\n",
    "#     # as timestamp is returned in ms, let us convert this back to proper timestamps.\n",
    "# #self.df.dateTime = pd.to_datetime(self.df.dateTime, unit='ms').dt.strftime(Constants.DateTimeFormat)\n",
    "# df = df.set_index('dateTime', inplace=True)\n",
    "\n",
    "#     # Get rid of columns we do not need\n",
    "# df = df.drop(['closeTime', 'quoteAssetVolume', 'numberOfTrades', 'takerBuyBaseVol','takerBuyQuoteVol', 'ignore'], axis=1)\n",
    "\n",
    "df = pd.read_csv(\"LTCUSDT-5m-2021-11.csv\")\n",
    "df.columns = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'count', 'taker_buy_volume', 'taker_buy_quote_volume', 'ignore']\n",
    "\n",
    "df = df.set_index('open_time')\n",
    "\n",
    "\n",
    "\n",
    "df = df.drop(['close_time', 'ignore'], axis=1)\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 26-day EMA of the closing price\n",
    "k = df['close'].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "# Get the 12-day EMA of the closing price\n",
    "d = df['close'].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "# Subtract the 26-day EMA from the 12-Day EMA to get the MACD\n",
    "macd = k - d\n",
    "# Get the 9-Day EMA of the MACD for the Trigger line\n",
    "macd_s = macd.ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "# Calculate the difference between the MACD - Trigger for the Convergence/Divergence value\n",
    "macd_h = macd - macd_s\n",
    "# Add all of our new values for the MACD to the dataframe\n",
    "df['macd'] = df.index.map(macd)\n",
    "df['macd_h'] = df.index.map(macd_h)\n",
    "df['macd_s'] = df.index.map(macd_s)\n",
    "\n",
    "#df.index = pd.DatetimeIndex(df['open_time'].to_period('M'))\n",
    "\n",
    "df.index = pd.to_datetime(df.index, unit='ms')\n",
    "df.index = pd.DatetimeIndex(df.index).to_period('M')\n",
    "\n",
    "df_test = df[floor(-0.1*len(df)): -1]\n",
    "df_train = df[0 : len(df_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Period'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/olegsandrr/Documents/MACD_Forecast/visualisation.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olegsandrr/Documents/MACD_Forecast/visualisation.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/olegsandrr/Documents/MACD_Forecast/visualisation.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(df[\u001b[39m\"\u001b[39;49m\u001b[39mmacd\u001b[39;49m\u001b[39m\"\u001b[39;49m][floor(\u001b[39m0.75\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mlen\u001b[39;49m(df)):floor(\u001b[39m0.85\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(df))])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olegsandrr/Documents/MACD_Forecast/visualisation.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[1;32m   2813\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1690\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m-> 1690\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_line(line)\n\u001b[1;32m   1691\u001b[0m \u001b[39mif\u001b[39;00m scalex:\n\u001b[1;32m   1692\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_autoscale_view(\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py:2304\u001b[0m, in \u001b[0;36m_AxesBase.add_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2301\u001b[0m \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2302\u001b[0m     line\u001b[39m.\u001b[39mset_clip_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch)\n\u001b[0;32m-> 2304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_line_limits(line)\n\u001b[1;32m   2305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mget_label():\n\u001b[1;32m   2306\u001b[0m     line\u001b[39m.\u001b[39mset_label(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_child\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py:2327\u001b[0m, in \u001b[0;36m_AxesBase._update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_line_limits\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[1;32m   2324\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m \u001b[39m    Figures out the data limit of the given line, updating self.dataLim.\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2327\u001b[0m     path \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mget_path()\n\u001b[1;32m   2328\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mvertices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2329\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/lines.py:1028\u001b[0m, in \u001b[0;36mLine2D.get_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx:\n\u001b[0;32m-> 1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecache()\n\u001b[1;32m   1029\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/lines.py:659\u001b[0m, in \u001b[0;36mLine2D.recache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m always \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx:\n\u001b[1;32m    658\u001b[0m     xconv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_xunits(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_xorig)\n\u001b[0;32m--> 659\u001b[0m     x \u001b[39m=\u001b[39m _to_unmasked_float_array(xconv)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m    660\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1340\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mfilled(np\u001b[39m.\u001b[39mnan)\n\u001b[1;32m   1339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1340\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(x, \u001b[39mfloat\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Period'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df[\"macd\"][floor(0.75*len(df)):floor(0.85 * len(df))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "features = df.copy()\n",
    "target = features['macd'].dropna()\n",
    "features = features[features[\"macd\"].notna()].drop(['macd', 'macd_h', 'macd_s'], axis=1)\n",
    "\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_transformed = lab.fit_transform(target)\n",
    "y_transformed\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree = dtree.fit(features, y_transformed)\n",
    "\n",
    "# tree.plot_tree(dtree, feature_names=features.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3053687909848462"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARIMA example\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train['macd'].dropna()[-100:]\n",
    "# fit model\n",
    "model = ARIMA(data, order=(2, 3, 1))\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "# yhat = model_fit.predict(len(data), len(data), type='levels')\n",
    "# print(yhat)\n",
    "\n",
    "prediction = model_fit.forecast(26)\n",
    "#df_test[:26]\n",
    "mean_squared_error(prediction, df_test[\"macd\"][0:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2030-03    0.029022\n",
       "2030-04    0.077647\n",
       "2030-05    0.125649\n",
       "2030-06    0.174529\n",
       "2030-07    0.223681\n",
       "2030-08    0.273345\n",
       "2030-09    0.323425\n",
       "2030-10    0.373959\n",
       "2030-11    0.424931\n",
       "2030-12    0.476349\n",
       "2031-01    0.528208\n",
       "2031-02    0.580512\n",
       "2031-03    0.633258\n",
       "2031-04    0.686447\n",
       "2031-05    0.740080\n",
       "2031-06    0.794156\n",
       "2031-07    0.848674\n",
       "2031-08    0.903636\n",
       "2031-09    0.959041\n",
       "2031-10    1.014889\n",
       "2031-11    1.071181\n",
       "2031-12    1.127915\n",
       "2032-01    1.185093\n",
       "2032-02    1.242713\n",
       "2032-03    1.300777\n",
       "2032-04    1.359284\n",
       "Freq: M, Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN - наверное слишком сильно для слабого ученика\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_train_test(url, split_percent=0.8):\n",
    "    df = pd.read_csv(url, usecols=[1], engine='python')\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    # Point for splitting data into train and test\n",
    "    split = int(n*split_percent)\n",
    "    train_data = data[range(split)]\n",
    "    test_data = data[split:]\n",
    "    return train_data, test_data, data\n",
    " \n",
    "# Prepare the input X and target Y\n",
    "def get_XY(dat, time_steps):\n",
    "    Y_ind = np.arange(time_steps, len(dat), time_steps)\n",
    "    Y = dat[Y_ind]\n",
    "    rows_x = len(Y)\n",
    "    X = dat[range(time_steps*rows_x)]\n",
    "    X = np.reshape(X, (rows_x, time_steps, 1))    \n",
    "    return X, Y\n",
    " \n",
    "def create_RNN(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, input_shape=input_shape, activation=activation[0]))\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    " \n",
    "def print_error(trainY, testY, train_predict, test_predict):    \n",
    "    # Error of predictions\n",
    "    train_rmse = math.sqrt(mean_squared_error(trainY, train_predict))\n",
    "    test_rmse = math.sqrt(mean_squared_error(testY, test_predict))\n",
    "    # Print RMSE\n",
    "    print('Train RMSE: %.3f RMSE' % (train_rmse))\n",
    "    print('Test RMSE: %.3f RMSE' % (test_rmse))    \n",
    " \n",
    "# Plot the result\n",
    "def plot_result(trainY, testY, train_predict, test_predict):\n",
    "    actual = np.append(trainY, testY)\n",
    "    predictions = np.append(train_predict, test_predict)\n",
    "    rows = len(actual)\n",
    "    plt.figure(figsize=(15, 6), dpi=80)\n",
    "    plt.plot(range(rows), actual)\n",
    "    plt.plot(range(rows), predictions)\n",
    "    plt.axvline(x=len(trainY), color='r')\n",
    "    plt.legend(['Actual', 'Predictions'])\n",
    "    plt.xlabel('Observation number after given time steps')\n",
    "    plt.ylabel('Sunspots scaled')\n",
    "    plt.title('Actual and Predicted Values. The Red Line Separates The Training And Test Examples')\n",
    " \n",
    "sunspots_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "time_steps = 12\n",
    "train_data, test_data, data = get_train_test(sunspots_url)\n",
    "trainX, trainY = get_XY(train_data, time_steps)\n",
    "testX, testY = get_XY(test_data, time_steps)\n",
    " \n",
    "# Create model and train\n",
    "model = create_RNN(hidden_units=3, dense_units=1, input_shape=(time_steps,1), \n",
    "                   activation=['tanh', 'tanh'])\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)\n",
    " \n",
    "# make predictions\n",
    "train_predict = model.predict(trainX)\n",
    "test_predict = model.predict(testX)\n",
    " \n",
    "# Print error\n",
    "print_error(trainY, testY, train_predict, test_predict)\n",
    " \n",
    "#Plot result\n",
    "plot_result(trainY, testY, train_predict, test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "В случае временных рядов берется разное количество обучающих примеров у слабых учеников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3053687909848462\n",
      "\n",
      "1.1825068860096115\n",
      "\n",
      "1.3822840918752244\n",
      "\n",
      "1.3387232595428888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28067222201958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.205049829530543\n",
      "\n",
      "1.2870085267975098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.288185105801851\n",
      "\n",
      "1.3491008763622536\n",
      "\n",
      "ensemble prediction: 1.1206614667387744\n"
     ]
    }
   ],
   "source": [
    "num_of_models = 10\n",
    "prediction_size = 26\n",
    "errors = np.empty(num_of_models)\n",
    "predictions = np.empty((num_of_models, prediction_size))\n",
    "#models = [num_of_models]\n",
    "\n",
    "\n",
    "for i in range(1, num_of_models):\n",
    "    data = df_train['macd'].dropna()[-100 * i:]\n",
    "    # fit model\n",
    "    models = ARIMA(data, order=(2, 3, 1))\n",
    "    model_fit = models.fit()\n",
    "    # make prediction\n",
    "\n",
    "    predictions[i - 1] = model_fit.forecast(prediction_size)\n",
    "    print(str(mean_squared_error(predictions[i - 1], df_test[\"macd\"][0:26])) + '\\n')\n",
    "\n",
    "ensemble_prediction = predictions.mean(0)\n",
    "print('ensemble prediction: ' + str(mean_squared_error(ensemble_prediction, df_test[\"macd\"][0:26])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best basic model prediction: 0.8193636981244415  ensemble prediction: 0.7236783941527759\n",
      "best basic model prediction: 1.8304812213807273  ensemble prediction: 2.239989334384835\n",
      "best basic model prediction: 0.9261651993164146  ensemble prediction: 1.0479033344670328\n",
      "best basic model prediction: 0.019802896109778735  ensemble prediction: 0.03670702973328946\n",
      "best basic model prediction: 3.688536345394365  ensemble prediction: 3.4681407932314054\n",
      "best basic model prediction: 0.06309060869286696  ensemble prediction: 0.08990957015139249\n",
      "best basic model prediction: 0.014783129492511315  ensemble prediction: 0.012484577890522246\n",
      "best basic model prediction: 0.1160572931871838  ensemble prediction: 0.2255134305370293\n",
      "best basic model prediction: 0.10151909730225868  ensemble prediction: 0.11966471551367651\n",
      "best basic model prediction: 0.4169172868959827  ensemble prediction: 0.38203710155591863\n",
      "best basic model prediction: 0.6685925943680832  ensemble prediction: 0.5903670930950984\n",
      "best basic model prediction: 0.2565708466280108  ensemble prediction: 0.3538668996863423\n",
      "best basic model prediction: 1.1011103140446157  ensemble prediction: 0.9471606784712239\n",
      "best basic model prediction: 0.06387586257483838  ensemble prediction: 0.05217874561803604\n",
      "best basic model prediction: 0.9002570642127263  ensemble prediction: 0.8221269952650974\n",
      "best basic model prediction: 1.584079688600082  ensemble prediction: 2.296286695835611\n",
      "best basic model prediction: 0.8445333131141606  ensemble prediction: 0.1207516784409231\n",
      "best basic model prediction: 1.7254407207468812  ensemble prediction: 1.7795327466676882\n",
      "best basic model prediction: 0.022344436830836166  ensemble prediction: 0.030600161931664465\n",
      "best basic model prediction: 0.19520886808556856  ensemble prediction: 0.21976358855866648\n",
      "best basic model prediction: 0.3087165396597529  ensemble prediction: 0.3292329595073226\n",
      "best basic model prediction: 2.741894609326192  ensemble prediction: 2.1773698317367707\n",
      "best basic model prediction: 0.22766620586563466  ensemble prediction: 0.2137188114004142\n",
      "best basic model prediction: 1.2035876454904646  ensemble prediction: 1.3535409756592556\n",
      "best basic model prediction: 0.09943290258792177  ensemble prediction: 0.10980243302624403\n",
      "best basic model prediction: 0.38061996501713746  ensemble prediction: 0.4449965958891266\n",
      "best basic model prediction: 0.1453615532042395  ensemble prediction: 0.21323210038200868\n",
      "best basic model prediction: 0.7942064450641712  ensemble prediction: 0.8440612943364031\n",
      "best basic model prediction: 0.011225646696544593  ensemble prediction: 0.01156128247203895\n",
      "best basic model prediction: 1.4953272666090025  ensemble prediction: 1.4635730043001887\n",
      "best basic model prediction: 0.3017111098873001  ensemble prediction: 0.32905582923066823\n",
      "best basic model prediction: 0.6778135536704449  ensemble prediction: 0.6314759625488987\n",
      "best basic model prediction: 1.2518970511134673  ensemble prediction: 1.159226663696011\n",
      "best basic model prediction: 0.167271023029917  ensemble prediction: 0.19404062584453388\n",
      "best basic model prediction: 0.06159979005928183  ensemble prediction: 0.061005654390260275\n",
      "best basic model prediction: 0.06284824949448971  ensemble prediction: 0.08227172215359538\n",
      "best basic model prediction: 0.6489546926401775  ensemble prediction: 0.6484700650963291\n",
      "best basic model prediction: 1.6848279572420684  ensemble prediction: 2.162864700036585\n",
      "best basic model prediction: 0.14594269025562928  ensemble prediction: 0.17725944009002975\n",
      "best basic model prediction: 0.05765351182767156  ensemble prediction: 0.1173049309787359\n",
      "best basic model prediction: 1.3050909315048362  ensemble prediction: 1.137371550450097\n",
      "best basic model prediction: 0.18318120340160585  ensemble prediction: 0.1792715465542384\n",
      "best basic model prediction: 2.987670357645879  ensemble prediction: 2.621096103762137\n",
      "best basic model prediction: 10  ensemble prediction: 16.523279546921902\n",
      "best basic model prediction: 0.08521468892687036  ensemble prediction: 0.09521756138310243\n",
      "best basic model prediction: 0.07421792507094668  ensemble prediction: 0.07945020812497973\n",
      "best basic model prediction: 0.16908298234753483  ensemble prediction: 0.1544384022464952\n",
      "best basic model prediction: 0.4668077473887529  ensemble prediction: 0.5416825083621305\n",
      "best basic model prediction: 0.6562810866820828  ensemble prediction: 0.6817050500119859\n",
      "best basic model prediction: 0.09129423640547946  ensemble prediction: 0.15510162926419074\n",
      "best basic model prediction: 1.8765549141228166  ensemble prediction: 1.7772483053320205\n",
      "best basic model prediction: 0.010399273218721543  ensemble prediction: 0.010490045686830441\n",
      "best basic model prediction: 0.04593070144660254  ensemble prediction: 0.07531029963941592\n",
      "best basic model prediction: 10  ensemble prediction: 312.16539623734815\n",
      "best basic model prediction: 10  ensemble prediction: 10.969516055626313\n",
      "best basic model prediction: 1.6261780440747389  ensemble prediction: 1.4757114904459487\n",
      "best basic model prediction: 2.079452354320635  ensemble prediction: 2.033110344627781\n",
      "best basic model prediction: 0.5214765453129858  ensemble prediction: 0.6763167243181202\n",
      "best basic model prediction: 0.34186561237386026  ensemble prediction: 0.6317327523631364\n",
      "best basic model prediction: 3.853937926385357  ensemble prediction: 4.059714481622702\n",
      "best basic model prediction: 0.7026654759411814  ensemble prediction: 0.6335752746286053\n",
      "best basic model prediction: 2.203414103446711  ensemble prediction: 2.0446008113059357\n",
      "best basic model prediction: 0.41503811747159863  ensemble prediction: 0.627605284617953\n",
      "best basic model prediction: 1.2506307448960103  ensemble prediction: 1.1027193840581246\n",
      "best basic model prediction: 1.424577483423922  ensemble prediction: 1.5376731331225142\n",
      "best basic model prediction: 0.39303265126990333  ensemble prediction: 0.38862333926184334\n",
      "best basic model prediction: 5.541228290141215  ensemble prediction: 5.392670545330768\n",
      "best basic model prediction: 1.0053865412137388  ensemble prediction: 1.3858389620568823\n",
      "best basic model prediction: 10  ensemble prediction: 41.398242441475695\n",
      "best basic model prediction: 7.9848069071633265  ensemble prediction: 6.836609585856181\n",
      "best basic model prediction: 1.286951701902304  ensemble prediction: 1.2385632423075643\n",
      "best basic model prediction: 0.17229764978913786  ensemble prediction: 0.19404978004838586\n",
      "best basic model prediction: 0.48017604387404933  ensemble prediction: 0.4331941633160871\n",
      "best basic model prediction: 1.0424495992918943  ensemble prediction: 0.8894219524990672\n",
      "best basic model prediction: 2.6942909592777777  ensemble prediction: 2.3356651208732906\n",
      "best basic model prediction: 10  ensemble prediction: 68.08879245530693\n",
      "best basic model prediction: 0.7417459861039225  ensemble prediction: 1.087194365775234\n",
      "best basic model prediction: 0.7611433005157071  ensemble prediction: 0.5671728824512973\n",
      "best basic model prediction: 8.76562346982163  ensemble prediction: 8.42371284564618\n",
      "best basic model prediction: 0.19323046994816712  ensemble prediction: 0.2375836937379492\n",
      "best basic model prediction: 1.1783343877287202  ensemble prediction: 0.901653715170955\n",
      "best basic model prediction: 10  ensemble prediction: 10.992063175082277\n",
      "best basic model prediction: 0.47574445645005997  ensemble prediction: 0.6989416371455837\n",
      "best basic model prediction: 1.2240842355744037  ensemble prediction: 1.1718739756527752\n",
      "best basic model prediction: 0.12106955818735245  ensemble prediction: 0.21200245726658917\n",
      "best basic model prediction: 0.08393065445368614  ensemble prediction: 0.081660732921756\n",
      "best basic model prediction: 0.082437237244503  ensemble prediction: 0.0866936898648565\n",
      "best basic model prediction: 0.0029502512374108957  ensemble prediction: 0.00858736951687013\n",
      "best basic model prediction: 0.0402217133672296  ensemble prediction: 0.057792252086441606\n",
      "best basic model prediction: 0.0025676259869490967  ensemble prediction: 0.003994821603500853\n",
      "best basic model prediction: 0.40823969442305497  ensemble prediction: 0.4609588636777284\n",
      "best basic model prediction: 0.029411754503904444  ensemble prediction: 0.0325358489830173\n",
      "best basic model prediction: 0.5069670616572337  ensemble prediction: 0.44468420118579094\n",
      "best basic model prediction: 1.3412753355216744  ensemble prediction: 1.1057801423986988\n",
      "best basic model prediction: 0.022811282393499475  ensemble prediction: 0.04528626827381233\n",
      "best basic model prediction: 1.0617078446925683  ensemble prediction: 0.993525036743493\n",
      "best basic model prediction: 1.0406667226357853  ensemble prediction: 0.8918312955637485\n",
      "best basic model prediction: 0.9493680011122141  ensemble prediction: 0.8657766961547017\n",
      "best basic model prediction: 1.898634018481253  ensemble prediction: 1.757205244933703\n",
      "\n",
      "44 out of 100 experiments showed better results with ensemble than with any basic model\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "\n",
    "def baggingARIMA():\n",
    "    num_of_models = 10\n",
    "    prediction_size = 26\n",
    "    num_of_steps = 100\n",
    "    errors = np.empty(num_of_models)\n",
    "    predictions = np.empty((num_of_models, prediction_size))\n",
    "    #models = [num_of_models]\n",
    "    counter = 0\n",
    "    for step in range(1, num_of_steps):\n",
    "        temp_test = df[floor(-0.009* step * len(df)): -1]\n",
    "        temp_train = df[0 : -len(temp_test)]\n",
    "        minSoleModel = 10\n",
    "        for i in range(1, num_of_models):\n",
    "            data = temp_train['macd'].dropna()[-100 * i:]\n",
    "            # fit model\n",
    "            models = ARIMA(data, order=(2, 3, 1))\n",
    "            model_fit = models.fit()\n",
    "            # make prediction\n",
    "\n",
    "            predictions[i - 1] = model_fit.forecast(prediction_size)\n",
    "            minSoleModel = min(mean_squared_error(predictions[i - 1], temp_test[\"macd\"][0:26]), minSoleModel)\n",
    "\n",
    "        ensemble_prediction = predictions.mean(0)\n",
    "        ensemble_error = mean_squared_error(ensemble_prediction, temp_test[\"macd\"][0:26])\n",
    "        print('best basic model prediction: ' + str(minSoleModel) + '  ensemble prediction: ' + str(ensemble_error))\n",
    "        if(ensemble_error < minSoleModel): counter += 1\n",
    "\n",
    "    print('\\n{0} out of {1} experiments showed better results with ensemble than with any basic model'.format(counter, num_of_steps))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    baggingARIMA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for n_estimators=1: 19.657759587971253\n",
      "MSE for n_estimators=100: 0.8697999402837402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6715/2097251924.py:46: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  predictions = np.sum((self.learning_rate * estimator.predict(X)\n"
     ]
    }
   ],
   "source": [
    "# Генерация синтетических данных\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X.squeeze() + 1 + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Определение базовой модели (слабого ученика)\n",
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.split_feature = None\n",
    "        self.split_threshold = None\n",
    "        self.left_value = None\n",
    "        self.right_value = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Простой ступенчатый классификатор\n",
    "        self.split_feature = 0\n",
    "        self.split_threshold = np.median(X)\n",
    "        self.left_value = np.mean(y[np.where(X <= self.split_threshold)[0]])\n",
    "        self.right_value = np.mean(y[np.where(X > self.split_threshold)[0]])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(X[:, self.split_feature] <= self.split_threshold,\n",
    "                        self.left_value, self.right_value)\n",
    "\n",
    "# Определение класса для градиентного бустинга\n",
    "class GradientBoostingRegressorHomemade:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Инициализация предсказаний нулевым значением\n",
    "        predictions = np.zeros_like(y)\n",
    "\n",
    "        # Обучение базовых моделей и обновление предсказаний\n",
    "        for _ in range(self.n_estimators):\n",
    "            estimator = DecisionStump()\n",
    "            residual = y - predictions\n",
    "            estimator.fit(X, residual)\n",
    "            predictions += self.learning_rate * estimator.predict(X)\n",
    "            self.estimators.append(estimator)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Суммируем предсказания от всех базовых моделей\n",
    "        predictions = np.sum((self.learning_rate * estimator.predict(X)\n",
    "                             for estimator in self.estimators), axis=0)\n",
    "        return predictions\n",
    "\n",
    "# Использование градиентного бустинга\n",
    "gb_regressor = GradientBoostingRegressorHomemade(n_estimators=100, learning_rate=0.1)\n",
    "gb_regressor.fit(X, y)\n",
    "basic_model = GradientBoostingRegressorHomemade(n_estimators=1, learning_rate=0.1)\n",
    "basic_model.fit(X, y)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Генерация случайных данных\n",
    "np.random.seed(59)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * (X.squeeze())**2 +  5 * X.squeeze() +  1 + 0.1 * np.random.randn(100)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Обучение модели с n_estimators=1\n",
    "model_1 = GradientBoostingRegressorHomemade(n_estimators=1, learning_rate=0.1)\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Обучение модели с n_estimators=100\n",
    "model_100 = GradientBoostingRegressorHomemade(n_estimators=100, learning_rate=0.1)\n",
    "model_100.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "predictions_1 = model_1.predict(X_test)\n",
    "predictions_100 = model_100.predict(X_test)\n",
    "\n",
    "# Вычисление MSE\n",
    "mse_1 = mean_squared_error(y_test, predictions_1)\n",
    "mse_100 = mean_squared_error(y_test, predictions_100)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"MSE for n_estimators=1: {mse_1}\")\n",
    "print(f\"MSE for n_estimators=100: {mse_100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.14879D+00    |proj g|=  2.53863D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      2     12      1     0     0   3.048D-04  -1.149D+00\n",
      "  F =  -1.1487925938544030     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/olegsandrr/.local/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.77219D+00    |proj g|=  1.41377D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      2     12      1     0     0   3.241D-03  -1.772D+00\n",
      "  F =  -1.7721958259936590     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "best basic model prediction: 0.23949592946788167  ensemble prediction: 0.3907426613901024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def differentModelsPredictions(prediction_size, data, test_data):\n",
    "\n",
    "    num_of_models = 5\n",
    "    predictions = np.empty((num_of_models, prediction_size))\n",
    "    # ARIMA\n",
    "    model = ARIMA(data, order=(2, 3, 1))\n",
    "    model_fit = model.fit()\n",
    "    predictions[0] =  model_fit.forecast(prediction_size)\n",
    "    CurMin = mean_squared_error(predictions[0], test_data)\n",
    "\n",
    "    #AR\n",
    "    model = AutoReg(data, lags=2)\n",
    "    model_fit = model.fit()\n",
    "    predictions[1] = model_fit.forecast(prediction_size)\n",
    "    CurMin = min(CurMin, mean_squared_error(predictions[1], test_data))\n",
    "\n",
    "    #MA\n",
    "    model = ARIMA(data, order=(0, 0, 1))\n",
    "    model_fit = model.fit()\n",
    "    predictions[2] = model_fit.forecast(prediction_size)\n",
    "    CurMin = min(CurMin, mean_squared_error(predictions[2], test_data))\n",
    "\n",
    "    #ARMA\n",
    "    model = ARIMA(data, order=(2, 0, 1))\n",
    "    model_fit = model.fit()\n",
    "    predictions[3] = model_fit.forecast(prediction_size)\n",
    "    CurMin = min(CurMin, mean_squared_error(predictions[3], test_data))\n",
    "\n",
    "    #SARIMA\n",
    "    model = SARIMAX(data, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
    "    model_fit = model.fit()\n",
    "    predictions[4] = model_fit.forecast(prediction_size)\n",
    "    CurMin = min(CurMin, mean_squared_error(predictions[4], test_data))\n",
    "\n",
    "    return predictions, CurMin\n",
    "\n",
    "\n",
    "\n",
    "temp_test = df[floor(-0.5* len(df)): ]\n",
    "temp_train = df[0 : -len(temp_test)]\n",
    "predictions_for_LR, mi = differentModelsPredictions(80, temp_train['macd'].dropna(), temp_test[\"macd\"][0:80])\n",
    "lr = LinearRegression().fit(predictions_for_LR.reshape(80, 5), temp_test[\"macd\"][0:80])\n",
    "\n",
    "predictionsFinal, mi = differentModelsPredictions(26, df_train['macd'].dropna()[-100 * 5:], df_test[\"macd\"][0:26])\n",
    "ensemble_prediction = predictionsFinal.mean(0)\n",
    "ensemble_error = mean_squared_error(ensemble_prediction, df_test[\"macd\"][0:26])\n",
    "print('best basic model prediction: ' + str(mi) + '  ensemble prediction: ' + str(ensemble_error) + '\\n')\n",
    "\n",
    "final_result = mean_squared_error(lr.predict(predictionsFinal.reshape(26, 5)), df_test[\"macd\"][0:26])\n",
    "print('meta learner final result: ' + str(final_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'num_leaves': 30,\n",
    "#           'n_estimators': 400,\n",
    "#           'max_depth': 8,\n",
    "#           'min_child_samples': 200,\n",
    "#           'learning_rate': 0.1,\n",
    "#           'subsample': 0.50,\n",
    "#           'colsample_bytree': 0.75\n",
    "#          }\n",
    "\n",
    "\n",
    "# model = lgb.LGBMRegressor(**params)\n",
    "# model = model.fit(x_train.drop(columns=['timestamp']), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time predictions\n",
    "\n",
    "Цикл, где я предсказываю некое количество шагов, потом двигаюсь на один период вперед и добавляю его к модели?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
